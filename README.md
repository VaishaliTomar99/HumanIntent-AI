# ğŸ§  HumanIntent-AI

A deep learning-based project focused on detecting human intention and violence using sequential video data.

---

## ğŸ“Œ Description
HumanIntent-AI uses a **CNN-LSTM architecture** to analyze video frames and classify human actions as **violent or non-violent**.  
The CNN extracts spatial features from individual frames, while the LSTM captures **temporal dependencies** across frame sequences.

The main application logic and model implementation are organized inside the **`src/` directory** for clarity and modularity.

---

## ğŸ“‚ Dataset Used
- **AIRT Lab â€“ Automatic Violence Detection in Videos Dataset**
- Contains labeled video clips of **violent and non-violent human activities**
- Used for training and evaluation of the CNN-LSTM model

ğŸ”— **Dataset Link:**  
https://www.kaggle.com/datasets/airtlab/automatic-violence-detection-in-videos

> âš ï¸ *The dataset is not included in this repository due to size and licensing constraints.*

---

## âœ¨ Features
- Human intention and violence detection
- Sequence-based video analysis
- CNN + LSTM deep learning architecture
- Real-time prediction interface using Streamlit
- Modular and organized code structure

---

## ğŸ› ï¸ Tech Stack
- Python  
- PyTorch  
- NumPy  
- Pandas  
- Streamlit  
- Matplotlib  

---

## ğŸ“Š Results & Observations

### ğŸ”¹ Training Performance
- **Training Loss:** Consistently decreases across epochs
- **Training Accuracy:** Reaches approximately **99%**
- **Validation Accuracy:** Stabilizes around **90â€“95%**

These results show that the model effectively learns **spatialâ€“temporal patterns** in video data, with minor fluctuations due to dataset complexity.

### ğŸ”¹ Training Graphs
The following graphs were generated during training:
- Training Loss vs Epochs
- Training Accuracy vs Validation Accuracy

ğŸ“Œ *(Add the training metrics image here)*  
```md
![Training Metrics](assest/graph.png)
